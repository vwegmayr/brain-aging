# rm -rf .smt /local/dhaziza && mkdir /local/dhaziza
# smt init -e python -m run.py -c store-diff -s /local/dhaziza/records dhaziza -d /local/dhaziza/data -l cmdline
#CUDA_VISIBLE_DEVICES=2 smt run -r "(new) AD v HC baseline" --config configs/example_config.yaml -S /local/dhaziza/data -a fit
#CUDA_VISIBLE_DEVICES=5 python run.py --config configs/example_config.yaml -S /local/dhaziza/data -a fit

class: src.estimator.Estimator
params:
  input_fn_config: # Parameters for input generation (gen_input_fn)
    data_generation:
      data_converted_directory: data/ready/
      train_database_file: train.tfrecord
      test_database_file: test.tfrecord
      image_shape:
        - 91
        - 109
        - 91
      dataset_compression: GZIP
      test_set_size_ratio: 0.2
      test_set_random_seed: 0
      data_sources:
        - name: ADNI_AIBL
          # Skip augmented data. Example file '273666_normalized.nii.gz'
          glob: /local/ADNI_AIBL/ADNI_AIBL_T1_normalized/train/[0-9]*[0-9]_normalized*
          features_from_filename:
            regexp: .*/(\d+)_normalized\.nii\.gz
            features_group:
              study_image_id: 1
          patients_features: data/raw/csv/adni_aibl.csv
        # - name: PPMI
        #   glob: /local/PPMI/mni_registered/I*.nii.gz
        #   features_from_filename:
        #     regexp: .*/I(\d+)\.nii\.gz
        #     features_group:
        #       study_image_id: 1
        #   patients_features: data/raw/csv/ppmi.csv
        # - name: KOLN_T1
        #   glob: data/raw/KOLN_T1/*/*/*.nii.gz
        #   features_from_filename:
        #     regexp: .*/(\d+)/(\d+)_t1\.nii\.gz
        #     features_group:
        #       study_image_id: 1
        #       study_patient_id: 2
        #   patients_features: data/raw/csv/koln.csv

    data_streaming:
      dataset:
        - call: prefetch
          buffer_size: 400
        - call: shuffle
          buffer_size: 100
          seed: 0
        - call: map
          map_func: src.input.parser
          num_parallel_calls: 8
        - call: filter
          keep_when_any_is_true:
            - health_ad
            - healthy
        - call: map
          map_func: src.input.distort
          num_parallel_calls: 8
        - call: batch
          batch_size: 8
  params: # Params for model (model_fn)
    train_log_every_n_iter: 5
    network_heads:
      # regressor:
      #   class: src.heads.regression.RegressionHead
      #   predict:
      #     - feature: age
      #       average: 75
      #   loss_weight_in_global_loss: 1
      #   head_l1_regularization: null
      #   train_only_globally: True
      classifier:
        class: src.heads.classification.ClassificationHead
        predict:
          - health_ad
          - healthy
        loss_weight_in_global_loss: 1
        head_l1_regularization: null
        train_only_globally: True
      adversarial:
        class: src.heads.categorical_variable_classification.CategoricalVariableClassificationHead
        predict: study_patient_id
        num_buckets: 200
        loss_weight_in_global_loss: null  # <= 0 for adv network
        head_l1_regularization: null
        train_only_globally: False
    network_train_ops_settings:
      alternative_training_steps: 0  # 1280
  run_config:
    num_epochs: 15
    validations_per_epoch: 2
    stats_backward_compatibility:
      # Classifier eval
      eval/classifier/accuracy: accuracy
      eval/classifier/false_negatives: false_negatives
      eval/classifier/false_positives: false_positives
      # Classifier training
      train/classifier/accuracy: train/accuracy
      train/classifier/false_negatives: train/false_negatives
      train/classifier/false_positives: train/false_positives
      # Global variables
      train/global_step: global_step
      train/adversarial/loss: adv_loss
      # Losses
      eval/global_optimizer_loss: opt_loss
      train/global_optimizer_loss: train/opt_loss
      eval/loss: loss
      train/classifier/loss: train/loss
      train/regressor/loss: train/loss
    # Tensorflow RunConfig
    # https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig
    tf_estimator_run_config:
      save_summary_steps: 1
      tf_random_seed: 40
      save_checkpoints_steps: 500
      #save_checkpoints_secs:
      keep_checkpoint_max: 5
      log_step_count_steps: 100
      keep_checkpoint_max: 2
      session_config:
        gpu_options:
          per_process_gpu_memory_fraction: 0.49
          allow_growth: False
