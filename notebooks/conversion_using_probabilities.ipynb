{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A VAGAN and a MCI/AD classifier are trained separately. Then the classifier is applied to the raw samples and the VAGAN preprocessed samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/local/home/mhoerold/entrack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import copy\n",
    "import pydoc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.test_retest.mri.supervised_features import SliceClassification\n",
    "from src.data.streaming.base import Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vagan_label = \"20180911-103911\"\n",
    "clf_label = \"20180909-113245\"\n",
    "conversion_delta = 4\n",
    "conversion_key = \"mci_ad_conv_delta_4\"\n",
    "test_file = \"data/20180909-083808/test.txt\"\n",
    "clf_folder = os.path.join(\"data\", clf_label)\n",
    "with open(os.path.join(clf_folder, \"config.yaml\"), 'r') as f:\n",
    "    clf_config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load classifier only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_only_config = copy.deepcopy(clf_config)\n",
    "clf_only_config[\"params\"][\"streamer\"][\"class\"] = \"src.data.streaming.mri_streaming.MRIConversionSingleStream\"\n",
    "clf_only_config[\"params\"][\"streamer\"][\"class\"] = pydoc.locate(clf_only_config[\"params\"][\"streamer\"][\"class\"])\n",
    "clf_only_config[\"params\"][\"streamer\"][\"params\"][\"stream_config\"][\"conversion_delta\"] = conversion_delta\n",
    "clf_only_config[\"params\"][\"streamer\"][\"params\"][\"stream_config\"][\"conversion_key\"] = \"mci_ad_conv_delta_4\"\n",
    "clf_only_config[\"params\"][\"streamer\"][\"params\"][\"stream_config\"][\"use_diagnoses\"] = [\"health_mci\", \"health_ad\"]\n",
    "\n",
    "clf_only_obj = SliceClassification(**clf_only_config[\"params\"])\n",
    "clf_only_est = tf.estimator.Estimator(\n",
    "    model_fn=clf_only_obj.model_fn,\n",
    "    model_dir=clf_folder,\n",
    "    params=clf_only_config[\"params\"][\"params\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load classifier with VAGAN preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_vagan_config = copy.deepcopy(clf_config)\n",
    "clf_vagan_config[\"params\"][\"streamer\"][\"class\"] = \"src.data.streaming.vagan_preprocessing.VaganConversionFarPredictions\"\n",
    "clf_vagan_config[\"params\"][\"streamer\"][\"class\"] = pydoc.locate(clf_vagan_config[\"params\"][\"streamer\"][\"class\"])\n",
    "clf_vagan_config[\"params\"][\"streamer\"][\"params\"][\"stream_config\"][\"conversion_delta\"] = conversion_delta\n",
    "clf_vagan_config[\"params\"][\"streamer\"][\"params\"][\"stream_config\"][\"conversion_key\"] = \"mci_ad_conv_delta_4\"\n",
    "clf_vagan_config[\"params\"][\"streamer\"][\"params\"][\"stream_config\"][\"vagan_steps\"] = 1\n",
    "clf_vagan_config[\"params\"][\"streamer\"][\"params\"][\"stream_config\"][\"vagan_label\"] = vagan_label\n",
    "clf_vagan_config[\"params\"][\"streamer\"][\"params\"][\"stream_config\"][\"cache_preprocessing\"] = False\n",
    "clf_vagan_config[\"params\"][\"streamer\"][\"params\"][\"stream_config\"][\"use_diagnoses\"] = [\"health_mci\", \"health_ad\"]\n",
    "\n",
    "clf_vagan_obj = SliceClassification(**clf_vagan_config[\"params\"])\n",
    "clf_vagan_est = tf.estimator.Estimator(\n",
    "    model_fn=clf_vagan_obj.model_fn,\n",
    "    model_dir=clf_folder,\n",
    "    params=clf_vagan_config[\"params\"][\"params\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = []\n",
    "with open(test_file, 'r') as f:\n",
    "    for line in f:\n",
    "        fid = line.strip()\n",
    "        file_ids.append(fid)\n",
    "        \n",
    "file_ids = clf_only_obj.streamer.select_file_ids(file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "labels = [clf_only_obj.streamer.get_meta_info_by_key(fid, conversion_key) for fid in file_ids]\n",
    "batches = [Group([fid]) for fid in file_ids]\n",
    "\n",
    "clf_input_fn = clf_only_obj.streamer.get_input_fn_for_groups(batches)\n",
    "\n",
    "vagan_input_fn = clf_vagan_obj.streamer.get_input_fn_for_groups(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probabilities(est, input_fn):\n",
    "    preds = est.predict(input_fn, [\"probs\"])\n",
    "    res = []\n",
    "    for pred in preds:\n",
    "        res.append(pred[\"probs\"][1])  ## probability of being AD\n",
    "        \n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0_probs = predict_probabilities(clf_only_est, clf_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vagan_probs = predict_probabilities(clf_vagan_est, vagan_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute true negative rate.\n",
    "    TN / (TN + FP)\n",
    "    \"\"\"\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    for y_t, y_p in zip(y_true, y_pred):\n",
    "        if y_t == 0 and y_p == 0:\n",
    "            TN += 1\n",
    "        if y_t == 0 and y_p == 1:\n",
    "            FP += 1\n",
    "\n",
    "    if TN + FP == 0:\n",
    "        return 0\n",
    "    return TN / (TN + FP)\n",
    "\n",
    "def compute_scores(y_true, y_pred):\n",
    "    funcs = [accuracy_score, recall_score, precision_score, specificity_score, f1_score]\n",
    "    scores = {}\n",
    "    names = []\n",
    "    for f in funcs:\n",
    "        s = f(y_true, y_pred)\n",
    "        fname = f.__name__.split(\"_\")[0]\n",
    "        scores[fname] = round(s, 5)\n",
    "        names.append(fname)\n",
    "        \n",
    "    return names, scores\n",
    "\n",
    "def threshold_diff(labels, t0_probs, vagan_probs):\n",
    "    all_eps = np.linspace(-1, 1, 200)\n",
    "    \n",
    "    expected = np.array(labels)\n",
    "    diffs = vagan_probs - t0_probs\n",
    "    accs = []\n",
    "    all_scores = []\n",
    "    best_score = {}\n",
    "    best_eps = {}\n",
    "    for eps in all_eps:\n",
    "        predicted_conv = (diffs > eps).astype(np.float32)\n",
    "        \n",
    "        acc = np.mean(predicted_conv == expected)\n",
    "        accs.append(acc)\n",
    "        \n",
    "        score_names, scores = compute_scores(labels, predicted_conv)\n",
    "        for name in score_names:\n",
    "            if name not in best_score:\n",
    "                best_score[name] = scores\n",
    "                best_eps[name] = eps\n",
    "            elif scores[name] > best_score[name][name]:\n",
    "                best_score[name] = scores\n",
    "                best_eps[name] = eps\n",
    "    \n",
    "    print(\"Max acc {} for eps {}\".format(np.max(accs), all_eps[np.argmax(accs)]))\n",
    "    for k, v in best_score.items():\n",
    "        print(\"scores for best {} (eps={})\".format(k, round(best_eps[k], 3)))\n",
    "        print(v)\n",
    "        \n",
    "    print(\"AUC score\")\n",
    "    print(roc_auc_score(labels, diffs))\n",
    "    plt.figure()\n",
    "    plt.plot(all_eps, accs, marker='o')\n",
    "    plt.show()\n",
    "    \n",
    "def threshold_vagan_prob(labels, vagan_probs):\n",
    "    all_eps = np.linspace(-1, 1, 200)\n",
    "    \n",
    "    expected = np.array(labels)\n",
    "    accs = []\n",
    "    all_scores = []\n",
    "    best_score = {}\n",
    "    best_eps = {}\n",
    "    for eps in all_eps:\n",
    "        predicted_conv = (vagan_probs > eps).astype(np.float32)\n",
    "        \n",
    "        acc = np.mean(predicted_conv == expected)\n",
    "        accs.append(acc)\n",
    "        \n",
    "        score_names, scores = compute_scores(labels, predicted_conv)\n",
    "        for name in score_names:\n",
    "            if name not in best_score:\n",
    "                best_score[name] = scores\n",
    "                best_eps[name] = eps\n",
    "            elif scores[name] > best_score[name][name]:\n",
    "                best_score[name] = scores\n",
    "                best_eps[name] = eps\n",
    "    \n",
    "    print(\"Max acc {} for eps {}\".format(np.max(accs), all_eps[np.argmax(accs)]))\n",
    "    for k, v in best_score.items():\n",
    "        print(\"scores for best {} (eps={})\".format(k, round(best_eps[k], 3)))\n",
    "        print(v)\n",
    "        \n",
    "    print(\"AUC score\")\n",
    "    print(roc_auc_score(labels, vagan_probs))\n",
    "    plt.figure()\n",
    "    plt.plot(all_eps, accs, marker='o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_diff(labels, t0_probs, vagan_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_vagan_prob(labels, vagan_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GT t1 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_fids = clf_only_obj.streamer.t1_fids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_batches = [Group([fid]) for fid in t1_fids]\n",
    "\n",
    "clf_t1_input_fn = clf_only_obj.streamer.get_input_fn_for_groups(t1_batches)\n",
    "t1_probs = predict_probabilities(clf_only_est, clf_t1_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for t0, t1, conv in zip(t0_probs, t1_probs, labels):\n",
    " #   print(\"{} {} {}\".format(t0, t1, conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_only_obj.streamer.get_exact_age(t1_fids[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_only_obj.streamer.get_exact_age(file_ids[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_diff(labels, t0_probs, t1_probs)\n",
    "threshold_vagan_prob(labels, t1_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine multiple time steps for final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input functions with different numbers of preprocessing steps\n",
    "delta_vagan_input_fn = {}\n",
    "for i in range(1, conversion_delta + 1):\n",
    "    fn = clf_vagan_obj.streamer.get_input_fn_for_groups(batches, vagan_steps=i)\n",
    "    delta_vagan_input_fn[i] = fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delta_to_probs = {}\n",
    "for i in range(1, conversion_delta + 1):\n",
    "    fn = delta_vagan_input_fn[i]\n",
    "    probs = predict_probabilities(clf_vagan_est, vagan_input_fn)\n",
    "    delta_to_probs[i] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs = np.zeros((len(labels), conversion_delta + 1))\n",
    "delta_to_probs[0] = t0_probs\n",
    "for i in range(0, conversion_delta + 1):\n",
    "    all_probs[:, i] = delta_to_probs[i][:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_diff(a):\n",
    "    return np.max(a) - np.min(a)\n",
    "\n",
    "def threshold_all_probs(labels, all_probs, agg_func):\n",
    "    all_eps = np.linspace(-1, 1, 200)\n",
    "    \n",
    "    expected = np.array(labels)\n",
    "    agg = np.apply_along_axis(agg_func, 1, all_probs)\n",
    "    accs = []\n",
    "    all_scores = []\n",
    "    best_score = {}\n",
    "    best_eps = {}\n",
    "    for eps in all_eps:\n",
    "        predicted_conv = (agg > eps).astype(np.float32)\n",
    "        \n",
    "        acc = np.mean(predicted_conv == expected)\n",
    "        accs.append(acc)\n",
    "        \n",
    "        score_names, scores = compute_scores(labels, predicted_conv)\n",
    "        for name in score_names:\n",
    "            if name not in best_score:\n",
    "                best_score[name] = scores\n",
    "                best_eps[name] = eps\n",
    "            elif scores[name] > best_score[name][name]:\n",
    "                best_score[name] = scores\n",
    "                best_eps[name] = eps\n",
    "    \n",
    "    print(\"Max acc {} for eps {}\".format(np.max(accs), all_eps[np.argmax(accs)]))\n",
    "    for k, v in best_score.items():\n",
    "        print(\"scores for best {} (eps={})\".format(k, round(best_eps[k], 3)))\n",
    "        print(v)\n",
    "        \n",
    "    print(\"AUC score\")\n",
    "    print(roc_auc_score(labels, agg))\n",
    "    plt.figure()\n",
    "    plt.plot(all_eps, accs, marker='o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_all_probs(labels, all_probs, np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_all_probs(labels, all_probs, np.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_all_probs(labels, all_probs, np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_all_probs(labels, all_probs, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_all_probs(labels, all_probs, max_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, probs in enumerate(all_probs):\n",
    "    print(\"{} {}\".format(np.std(probs), labels[i]))\n",
    "    print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(all_probs[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
